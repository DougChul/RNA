{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n",
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 0,\n",
    "    \"cutoff_date\": \"2020-01-01\",\n",
    "    \"test_cutoff_date\": \"2022-05-01\",\n",
    "    \"max_len\": 384,  ##\n",
    "    \"batch_size\": 1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"mixed_precision\": \"bf16\",\n",
    "    \"model_config_path\": \"../working/configs/pairwise.yaml\",  # Adjust path as needed\n",
    "    \"epochs\": 10,  ##\n",
    "    \"loss_power_scale\": 1.0,\n",
    "    \"max_cycles\": 1,\n",
    "    \"grad_clip\": 0.1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"d_clamp\": 30,\n",
    "    \"max_len_filter\": 9999999,\n",
    "    \"min_len_filter\": 10,\n",
    "    \"structural_violation_epoch\": 50,\n",
    "    \"balance_weight\": False,\n",
    "    \"n_tokens\": 4,\n",
    "    \"d_model\": 256,  ##\n",
    "    \"n_heads\": 8,\n",
    "    \"dropout\": 0.1,\n",
    "    \"d_ff\": 1024, ##\n",
    "    \"norm_ratio\": 0.25, ##\n",
    "    \"n_layers\": 20 ##\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Sample Data To make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\solba\\\\Desktop\\\\25_1_Capstone1\\\\WuSubSol'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID resname  resid    x_1    y_1     z_1    x_2    y_2     z_2  \\\n",
      "0   124D_B_9       C      9 -0.471 -6.788  18.299 -0.471 -6.788  18.299   \n",
      "1  124D_B_10       A     10 -5.581 -5.427  16.282 -5.581 -5.427  16.282   \n",
      "2  124D_B_11       U     11 -7.964 -1.483  13.892 -7.964 -1.483  13.892   \n",
      "3  124D_B_12       G     12 -8.050  3.242  11.526 -8.050  3.242  11.526   \n",
      "4  124D_B_13       U     13 -5.350  7.000   8.973 -5.350  7.000   8.973   \n",
      "\n",
      "     x_3    y_3     z_3    x_4    y_4     z_4    x_5    y_5     z_5  \n",
      "0 -0.471 -6.788  18.299 -0.471 -6.788  18.299 -0.471 -6.788  18.299  \n",
      "1 -5.581 -5.427  16.282 -5.581 -5.427  16.282 -5.581 -5.427  16.282  \n",
      "2 -7.964 -1.483  13.892 -7.964 -1.483  13.892 -7.964 -1.483  13.892  \n",
      "3 -8.050  3.242  11.526 -8.050  3.242  11.526 -8.050  3.242  11.526  \n",
      "4 -5.350  7.000   8.973 -5.350  7.000   8.973 -5.350  7.000   8.973  \n",
      "  target_id               sequence temporal_cutoff  description  all_sequences\n",
      "0    124D_B               CAUGUGAC      1993-05-07          NaN            NaN\n",
      "1    176D_B                 GAGUUC      1994-05-17          NaN            NaN\n",
      "2    17RA_A  GGCGUAAGGAUUACCUAUGCC      1998-08-04          NaN            NaN\n",
      "3    1A1T_B   GGACUAGCGGAGGCUAGUCC      1997-12-15          NaN            NaN\n",
      "4    1A3M_A         GGCGUCACACCUUC      1998-01-22          NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "folder_path = '../pdb_pipeline'\n",
    "\n",
    "train_labels = pd.read_csv(os.path.join(folder_path, 'pdb_labels_5models.csv'))\n",
    "\n",
    "train_sequences = pd.read_csv(os.path.join(folder_path, 'pdb_sequences_5models.csv'))\n",
    "\n",
    "print(train_labels.head())\n",
    "\n",
    "print(train_sequences.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         124D_B\n",
       "1         124D_B\n",
       "2         124D_B\n",
       "3         124D_B\n",
       "4         124D_B\n",
       "           ...  \n",
       "250737    9MX5_C\n",
       "250738    9MX5_C\n",
       "250739    9MX5_C\n",
       "250740    9MX5_C\n",
       "250741    9MX5_C\n",
       "Name: pdb_id, Length: 250742, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"pdb_id\"] = train_labels[\"ID\"].apply(lambda x: x.split(\"_\")[0]+'_'+x.split(\"_\")[1])\n",
    "train_labels[\"pdb_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3806/3806 [00:40<00:00, 94.02it/s] \n"
     ]
    }
   ],
   "source": [
    "all_xyz=[]\n",
    "\n",
    "for pdb_id in tqdm(train_sequences['target_id']):\n",
    "    df = train_labels[train_labels[\"pdb_id\"]==pdb_id]\n",
    "    #break\n",
    "    xyz=df[['x_1','y_1','z_1','x_2','y_2','z_2','x_3','y_3','z_3','x_4','y_4','z_4','x_5','y_5','z_5',]].to_numpy().astype('float32')\n",
    "    xyz[xyz<-1e17]=float('Nan');\n",
    "    all_xyz.append(xyz)\n",
    "\n",
    "# all_xyz[13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in train: 2900\n",
      "remain sequences: 2533\n"
     ]
    }
   ],
   "source": [
    "# filter the data\n",
    "# Filter and process data\n",
    "filter_nan = []\n",
    "max_len = 0\n",
    "filter_ratio = 0 # All data are valid\n",
    "for xyz in all_xyz:\n",
    "    if len(xyz) > max_len:\n",
    "        max_len = len(xyz)\n",
    "\n",
    "    filter_nan.append((np.isnan(xyz).mean() <= filter_ratio) & \\\n",
    "                      (len(xyz)<config['max_len_filter']) & \\\n",
    "                      (len(xyz)>config['min_len_filter']))\n",
    "\n",
    "\n",
    "print(f\"Longest sequence in train: {max_len}\")\n",
    "\n",
    "filter_nan = np.array(filter_nan)\n",
    "non_nan_indices = np.arange(len(filter_nan))[filter_nan]\n",
    "print('remain sequences:', len(non_nan_indices))\n",
    "train_sequences = train_sequences.loc[non_nan_indices].reset_index(drop=True)\n",
    "non_nan_xyz=[all_xyz[i] for i in non_nan_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1A1T_B\n",
      "GGACUAGCGGAGGCUAGUCC\n",
      "1997-12-15\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "#pack data into a dictionary\n",
    "\n",
    "data={\n",
    "      \"pdb_id\":train_sequences['target_id'].to_list(),\n",
    "      \"sequence\":train_sequences['sequence'].to_list(),\n",
    "      \"temporal_cutoff\": train_sequences['temporal_cutoff'].to_list(),\n",
    "      \"description\": train_sequences['description'].to_list(),\n",
    "      \"all_sequences\": train_sequences['all_sequences'].to_list(),\n",
    "      \"xyz\": non_nan_xyz\n",
    "}\n",
    "print(data['pdb_id'][1])\n",
    "print(data['sequence'][1])\n",
    "print(data['temporal_cutoff'][1])\n",
    "print(data['description'][1])\n",
    "print(data['all_sequences'][1])\n",
    "# print(data['xyz'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train / Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "all_index = np.arange(len(data['sequence']))\n",
    "cutoff_date = pd.Timestamp(config['cutoff_date'])\n",
    "test_cutoff_date = pd.Timestamp(config['test_cutoff_date'])\n",
    "train_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) <= cutoff_date]\n",
    "test_index = [i for i, d in enumerate(data['temporal_cutoff']) if pd.Timestamp(d) > cutoff_date and pd.Timestamp(d) <= test_cutoff_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ast import literal_eval\n",
    "\n",
    "def get_ct(bp,s):\n",
    "    ct_matrix=np.zeros((len(s),len(s)))\n",
    "    for b in bp:\n",
    "        ct_matrix[b[0]-1,b[1]-1]=1\n",
    "    return ct_matrix\n",
    "\n",
    "class RNA3D_Dataset(Dataset):\n",
    "    def __init__(self,indices,data):\n",
    "        self.indices=indices\n",
    "        self.data=data\n",
    "        self.tokens={nt:i for i,nt in enumerate('ACGU')}\n",
    "        # self.tokens = {'A': 2, 'U':-2, 'G':3, 'C':-3}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx=self.indices[idx]\n",
    "        sequence=[self.tokens[nt] for nt in (self.data['sequence'][idx])]\n",
    "        sequence=np.array(sequence)\n",
    "        sequence=torch.tensor(sequence)\n",
    "\n",
    "        #get C1' xyz\n",
    "        xyz=self.data['xyz'][idx]\n",
    "        xyz=torch.tensor(np.array(xyz))\n",
    "\n",
    "\n",
    "        if len(sequence)>config['max_len']:\n",
    "            crop_start=np.random.randint(len(sequence)-config['max_len'])\n",
    "            crop_end=crop_start+config['max_len']\n",
    "\n",
    "            sequence=sequence[crop_start:crop_end]\n",
    "            xyz=xyz[crop_start:crop_end]\n",
    "        #center at first atom if first atom does not exit go until it does\n",
    "        for i in range(len(xyz)):\n",
    "            if (~torch.isnan(xyz[i])).all():\n",
    "                break\n",
    "        xyz=xyz-xyz[i]\n",
    "\n",
    "        return {'pbd_id':self.data['pdb_id'][idx],\n",
    "            'sequence':sequence,\n",
    "                'xyz':xyz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=RNA3D_Dataset(train_index,data)\n",
    "val_dataset=RNA3D_Dataset(test_index,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.5840,  -1.9270,  -0.0570, -10.9290,   2.5640,   2.3630, -11.3600,\n",
      "         -4.0740,  -0.0880, -10.9900,   2.7140,   1.7140, -10.7080,   4.4850,\n",
      "         -0.1930])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['xyz'][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.5840,  -1.9270,  -0.0570, -10.9290,   2.5640,   2.3630, -11.3600,\n",
      "         -4.0740,  -0.0880, -10.9900,   2.7140,   1.7140, -10.7080,   4.4850,\n",
      "         -0.1930])\n"
     ]
    }
   ],
   "source": [
    "train_loader=DataLoader(train_dataset,batch_size=1,shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=1,shuffle=False)\n",
    "\n",
    "print(train_dataset[0]['xyz'][2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with one data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 0, 1, 3, 0, 2, 1, 2, 2, 0, 2, 2, 1, 3, 0, 2, 3, 1, 1]) 20\n",
      "1A1T_B\n"
     ]
    }
   ],
   "source": [
    "num_seq = 1\n",
    "\n",
    "src = train_dataset[num_seq]['sequence']\n",
    "tgt = train_dataset[num_seq]['xyz']\n",
    "\n",
    "print(src, len(src))\n",
    "print(train_dataset[num_seq]['pbd_id'])\n",
    "# print(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Pairwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "GGCGUAAGGAUUACCUAUGCC\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([21, 21])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import RNA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "src = torch.tensor([2, 2, 1, 2, 3, 0, 0, 2, 2, 0, 3, 3, 0, 1, 1, 3, 0, 3, 2, 1, 1], dtype=torch.long)\n",
    "# AUGC를 0123으로 매핑\n",
    "nucleotide_map = {0: 'A', 1: 'C', 2: 'G', 3: 'U'}\n",
    "\n",
    "str_A = ''.join([nucleotide_map[x.item()] for x in src])\n",
    "\n",
    "print(len(str_A))\n",
    "print(str_A)\n",
    "\n",
    "md = RNA.md()\n",
    "\n",
    "fc = RNA.fold_compound(str_A, md)\n",
    "\n",
    "# predict Minmum Free Energy and corresponding secondary structure\n",
    "# (ss, mfe) = \n",
    "# print(fc.mfe())\n",
    "fc.pf()\n",
    "B = torch.tensor(fc.bpp())\n",
    "\n",
    "# B = torch.tensor(B)\n",
    "B = B[1:,1:]\n",
    "print(type(B))\n",
    "print(B.shape)\n",
    "B = B + B.T\n",
    "# B = np.array(B, dtype=np.bool())\n",
    "# print(B)\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(B, cmap='viridis', annot=False)  # annot=True로 설정하면 각 셀에 값 표시\n",
    "plt.title('Pairwise Contact Probability Matrix')\n",
    "plt.show()\n",
    "\n",
    "# def get_pairwise_features(src, seq_len, d_model):\n",
    "#     nucleotide_map = {0: 'A', 1: 'C', 2: 'G', 3: 'U'}\n",
    "\n",
    "#     # print(\"pairwise\",src)\n",
    "#     src = src.squeeze(0)\n",
    "#     str_seq = ''.join([nucleotide_map[x.item()] for x in src])\n",
    "#     # print(\"str_seq\",str_seq)\n",
    "    \n",
    "#     md = RNA.md()\n",
    "#     fc = RNA.fold_compound(str_seq, md)\n",
    "#     fc.pf() ##???\n",
    "\n",
    "#     pair_matrix = torch.tensor(fc.bpp(), dtype=torch.float32)\n",
    "#     # print(\"pair_matrix\",pair_matrix)\n",
    "#     pair_matrix = pair_matrix[1:,1:] # remove first row and column 0 index in bpp is always 0\n",
    "#     pair_matrix = pair_matrix + pair_matrix.T # symmetric matrix\n",
    "\n",
    "#     pair_matrix = pair_matrix.unsqueeze(0).unsqueeze(0)\n",
    "#     pair_matrix = F.interpolate(pair_matrix, size=(d_model, d_model), mode='bilinear', align_corners=False)\n",
    "#     # pair_matrix = F.interpolate(pair_matrix, size=(d_model, d_model), mode='nearest', align_corners=False)\n",
    "\n",
    "#     pair_matrix = pair_matrix.squeeze()\n",
    "#     # print(\"pair_matrix\",pair_matrix.shape)\n",
    "\n",
    "#     return pair_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSA Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OuterProductMean(nn.Module):\n",
    "    def __init__(self, in_dim=256, dim_msa=32, pairwise_dim=64):\n",
    "        super(OuterProductMean, self).__init__()\n",
    "        self.proj_down1 = nn.Linear(in_dim, dim_msa)\n",
    "        self.proj_down2 = nn.Linear(dim_msa ** 2, pairwise_dim)\n",
    "\n",
    "    def forward(self,seq_rep, pair_rep=None):\n",
    "        seq_rep=self.proj_down1(seq_rep)\n",
    "        outer_product = torch.einsum('bid,bjc -> bijcd', seq_rep, seq_rep)\n",
    "        outer_product = rearrange(outer_product, 'b i j c d -> b i j (c d)')\n",
    "        outer_product = self.proj_down2(outer_product)\n",
    "\n",
    "        if pair_rep is not None:\n",
    "            outer_product=outer_product+pair_rep\n",
    "\n",
    "        return outer_product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Bone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import RNA\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat, reduce\n",
    "\n",
    "\n",
    "def pos_encoder(seq_len, d_model):\n",
    "    result = torch.zeros(seq_len, d_model)\n",
    "\n",
    "    for pos in range(seq_len):\n",
    "        for i in range(d_model):\n",
    "            if i % 2 == 0:\n",
    "                result[pos][i] = np.sin(pos / (10000 ** (i / d_model)))\n",
    "            else:\n",
    "                result[pos][i] = np.cos(pos / (10000 ** ((i - 1) / d_model)))\n",
    "\n",
    "    return result\n",
    "\n",
    "class RelativePositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_relative_position=32):\n",
    "        super().__init__()\n",
    "        self.max_relative_position = max_relative_position\n",
    "        # 상대적 위치 범위: [-max_relative_position, max_relative_position]\n",
    "        self.num_positions = 2 * max_relative_position + 1\n",
    "        self.relative_embedding = nn.Embedding(self.num_positions, d_model)\n",
    "        \n",
    "    def forward(self, seq_len):\n",
    "        # 모든 가능한 위치 쌍 간의 상대적 거리 계산\n",
    "        range_vec = torch.arange(seq_len)\n",
    "        distance_mat = range_vec[:, None] - range_vec[None, :]  # shape: [seq_len, seq_len]\n",
    "        \n",
    "        # 상대 거리를 [-max_relative_position, max_relative_position] 범위로 제한\n",
    "        distance_mat_clipped = torch.clamp(\n",
    "            distance_mat, -self.max_relative_position, self.max_relative_position)\n",
    "        \n",
    "        # 인덱스 변환: [-max_relative_position, max_relative_position] -> [0, 2*max_relative_position]\n",
    "        final_mat = distance_mat_clipped + self.max_relative_position\n",
    "        \n",
    "        # 상대적 위치에 대한 임베딩 조회\n",
    "        embeddings = self.relative_embedding(final_mat.to(torch.long))\n",
    "        \n",
    "        return embeddings  # shape: [seq_len, seq_len, d_model]\n",
    "\n",
    "class ConstrainedPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_relative_position=32, constrained_position=4):\n",
    "        super().__init__()\n",
    "        self.max_relative_position = max_relative_position\n",
    "        self.relative_embedding = nn.Embedding(2 * max_relative_position + 1, d_model)\n",
    "        self.constrained_position = constrained_position\n",
    "\n",
    "    def forward(self, seq_len):\n",
    "\n",
    "        return pos_encoding(seq_len, self.d_model)\n",
    "        \n",
    "\n",
    "class EmbedSequence(nn.Module):\n",
    "    def __init__(self, d_model, n_tokens = config['n_tokens']):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(n_tokens, d_model)\n",
    "        # self.pos_encoding = PosEncoding(seq_len, d_model)\n",
    "        \n",
    "    def forward(self, sequence):\n",
    "        seq_len = len(sequence.squeeze())\n",
    "        # print(seq_len)\n",
    "        pos_encoding = pos_encoder(seq_len, self.d_model)\n",
    "        sequence = sequence.long()\n",
    "        return self.embedding(sequence) + pos_encoding\n",
    "    \n",
    "\n",
    "class MultiheadAtt(nn.Module):\n",
    "    def __init__(self, d_model, n_heads=8, dropout=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_k = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_v = nn.Linear(d_model, n_heads * self.d_head)\n",
    "\n",
    "        # self.w_o = nn.Linear(n_heads * self.d_head, d_model)\n",
    "        \n",
    "    def forward(self, query, key, value):\n",
    "        # print('query.shape',query.shape)\n",
    "        batch_size, length, d_model = query.size()\n",
    "        \n",
    "        q = self.w_q(query)\n",
    "        k = self.w_k(key)\n",
    "        v = self.w_v(value)\n",
    "\n",
    "        q = q.view(batch_size, length, self.n_heads, self.d_head)\n",
    "        k = k.view(batch_size, length, self.n_heads, self.d_head)\n",
    "        v = v.view(batch_size, length, self.n_heads, self.d_head)\n",
    "\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)  \n",
    "        output = torch.matmul(scores, v)\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, length, -1)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.w_1(x)\n",
    "        x = self.activation(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = self.w_2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def residual_connection_one(x, sublayer):\n",
    "    return x + sublayer(x)\n",
    "\n",
    "def residual_connection_attention(x, sublayer):\n",
    "    return x + sublayer(x,x,x)\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, dropout=0, norm_type='post_ln'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_ff = config['d_ff']\n",
    "        \n",
    "        if (norm_type == 'post_ln') or (norm_type == 'pre_ln'):\n",
    "            self.norm_type = norm_type\n",
    "        else:\n",
    "            raise ValueError(\"Invalid norm_type\")\n",
    "\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.attention = MultiheadAtt(d_model, n_heads, dropout)\n",
    "        self.feedforward = FeedForward(d_model, self.d_ff, dropout)\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, src, pairwise_feature=None):\n",
    "        # src = residual_connection(src, self.encoder(src))\n",
    "        norm_type = self.norm_type\n",
    "\n",
    "        if norm_type == 'post_ln':\n",
    "            src = residual_connection_attention(src, self.attention)\n",
    "            src = self.norm_1(src)\n",
    "            src = self.activation(src)\n",
    "            src = residual_connection_one(src, self.feedforward)\n",
    "            src = self.norm_2(src)\n",
    "            src = self.activation(src)\n",
    "\n",
    "        elif norm_type == 'pre_ln':\n",
    "            src_temp = src\n",
    "            src = self.norm_1(src)\n",
    "            src = self.attention(src,src,src) + src_temp\n",
    "            src = self.activation(src)\n",
    "            src_temp = src\n",
    "            src = self.norm_2(src)\n",
    "            src = self.feedforward(src) + src_temp\n",
    "            src = self.activation(src)\n",
    "\n",
    "        return src\n",
    "\n",
    "\n",
    "class WuSubSol(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(WuSubSol, self).__init__()\n",
    "        self.config = config\n",
    "        self.n_layers = config['n_layers']\n",
    "        self.d_model = config['d_model']\n",
    "\n",
    "        self.norm_ratio = config['norm_ratio']\n",
    "        if (self.n_layers * self.norm_ratio).is_integer():\n",
    "            self.n_post_ln = int(self.n_layers * self.norm_ratio)\n",
    "        else:\n",
    "            print(\"Invalid norm_ratio\")\n",
    "            exit()\n",
    "        \n",
    "        self.embedding = EmbedSequence(self.d_model)\n",
    "\n",
    "\n",
    "        self.encoder_layers = []\n",
    "        for i in range(self.n_post_ln):\n",
    "            self.encoder_layers.append(EncoderLayer(self.d_model, config['n_heads'], config['dropout'], 'post_ln'))\n",
    "        for i in range(self.n_layers - self.n_post_ln):\n",
    "            self.encoder_layers.append(EncoderLayer(self.d_model, config['n_heads'], config['dropout'], 'pre_ln'))\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList(self.encoder_layers)\n",
    "\n",
    "        self.final_linear = nn.Linear(self.d_model, 15)\n",
    "\n",
    "        print(f\"{self.n_layers} layers of encoder constructed\")\n",
    "\n",
    "    def forward(self, src):\n",
    "        pairwise_feature = None\n",
    "\n",
    "        src = self.embedding(src) # L*d_model\n",
    "        # print('after embedding', src.shape)\n",
    "\n",
    "\n",
    "        for i,layer in enumerate(self.encoder_layers):\n",
    "            # print(\"before\",src.shape)\n",
    "            src = layer(src, pairwise_feature)\n",
    "            # print(\"after\",src.shape)\n",
    "\n",
    "        src = self.final_linear(src).squeeze()\n",
    "        \n",
    "        # print('final tensor-Shape : ', src.shape)\n",
    "\n",
    "        return src\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 layers of encoder constructed\n",
      "WuSubSol(\n",
      "  (embedding): EmbedSequence(\n",
      "    (embedding): Embedding(4, 256)\n",
      "  )\n",
      "  (encoder_layers): ModuleList(\n",
      "    (0-19): 20 x EncoderLayer(\n",
      "      (norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (attention): MultiheadAtt(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (w_q): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (w_k): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (w_v): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (feedforward): FeedForward(\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (w_1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (w_2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (activation): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=256, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = WuSubSol(config)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 layers of encoder constructed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torchviz import make_dot\n",
    "A = torch.tensor([2, 2, 1, 2, 3, 0, 0, 2, 2, 0, 3, 3, 0, 1, 1, 3, 0, 3, 2, 1, 1], dtype=torch.float32, requires_grad=True)\n",
    "A = A.unsqueeze(0) # batch dim 반영\n",
    "model = WuSubSol(config)\n",
    "# 모델에 맞는 더미 입력 데이터 생성\n",
    "\n",
    "y = model(A)\n",
    "# make_dot(y, params=dict(list(model.named_parameters()) + [('x', A)]))\n",
    "# make_dot(y.mean(), params=dict(list(model.named_parameters()) + [('x', A)]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance_matrix(X,Y,epsilon=1e-4):\n",
    "    return (torch.square(X[:,None]-Y[None,:])+epsilon).sum(-1).sqrt()\n",
    "\n",
    "def dRMAE(pred_x,\n",
    "          pred_y,\n",
    "          gt_x,\n",
    "          gt_y,\n",
    "          epsilon=1e-4,Z=10,d_clamp=None):\n",
    "    pred_dm=calculate_distance_matrix(pred_x,pred_y)\n",
    "    gt_dm=calculate_distance_matrix(gt_x,gt_y)\n",
    "\n",
    "    mask=~torch.isnan(gt_dm)\n",
    "    mask[torch.eye(mask.shape[0]).bool()]=False\n",
    "\n",
    "    rmsd=torch.abs(pred_dm[mask]-gt_dm[mask])\n",
    "\n",
    "    return rmsd.mean()/Z\n",
    "\n",
    "def align_svd_mae(input, target, Z=10):\n",
    "    \"\"\"\n",
    "    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n",
    "    and computes RMSD loss.\n",
    "\n",
    "    Args:\n",
    "        input (torch.Tensor): Nx3 tensor representing the input points.\n",
    "        target (torch.Tensor): Nx3 tensor representing the target points.\n",
    "\n",
    "    Returns:\n",
    "        aligned_input (torch.Tensor): Nx3 aligned input.\n",
    "        rmsd_loss (torch.Tensor): RMSD loss.\n",
    "    \"\"\"\n",
    "    # print('input-Shape', input.shape)\n",
    "    # print('output-Shape', target.shape)\n",
    "    # target = target[:, :3]\n",
    "    assert input.shape == target.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    #mask\n",
    "    mask=~torch.isnan(target.sum(-1))\n",
    "\n",
    "    input=input[mask]\n",
    "    target=target[mask]\n",
    "\n",
    "    # Compute centroids\n",
    "    centroid_input = input.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input - centroid_input.detach()\n",
    "    target_centered = target - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (det(R) = 1, no reflection)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt @ U.T\n",
    "\n",
    "    # Rotate input\n",
    "    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n",
    "\n",
    "    # # Compute RMSD loss\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # return aligned_input, rmsd_loss\n",
    "    return torch.abs(aligned_input-target).mean()/Z\n",
    "\n",
    "def align_svd_rmsd(input, target):\n",
    "    \"\"\"\n",
    "    Aligns the input (Nx3) to target (Nx3) using SVD-based Procrustes alignment\n",
    "    and computes RMSD loss.\n",
    "\n",
    "    Args:\n",
    "        input (torch.Tensor): Nx3 tensor representing the input points.\n",
    "        target (torch.Tensor): Nx3 tensor representing the target points.\n",
    "\n",
    "    Returns:\n",
    "        aligned_input (torch.Tensor): Nx3 aligned input.\n",
    "        rmsd_loss (torch.Tensor): RMSD loss.\n",
    "    \"\"\"\n",
    "    # print('input-Shape', input.shape)\n",
    "    # print('output-Shape', target.shape)\n",
    "    # target = target[:,:3]\n",
    "    assert input.shape == target.shape, \"Input and target must have the same shape\"\n",
    "\n",
    "    #mask\n",
    "    mask=~torch.isnan(target.sum(-1))\n",
    "    \n",
    "    \n",
    "    input=input[mask]\n",
    "    target=target[mask]\n",
    "\n",
    "    # Compute centroids\n",
    "    centroid_input = input.mean(dim=0, keepdim=True)\n",
    "    centroid_target = target.mean(dim=0, keepdim=True)\n",
    "\n",
    "    # Center the points\n",
    "    input_centered = input - centroid_input.detach()\n",
    "    target_centered = target - centroid_target\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = input_centered.T @ target_centered\n",
    "\n",
    "    # SVD to find optimal rotation\n",
    "    U, S, Vt = torch.svd(cov_matrix)\n",
    "\n",
    "    # Compute rotation matrix\n",
    "    R = Vt @ U.T\n",
    "\n",
    "    # Ensure a proper rotation (det(R) = 1, no reflection)\n",
    "    if torch.det(R) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R = Vt @ U.T\n",
    "\n",
    "    # Rotate input\n",
    "    aligned_input = (input_centered @ R.T.detach()) + centroid_target.detach()\n",
    "\n",
    "    # # Compute RMSD loss\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # rmsd_loss = torch.sqrt(((aligned_input - target) ** 2).mean())\n",
    "\n",
    "    # return aligned_input, rmsd_loss\n",
    "    return torch.square(aligned_input-target).mean().sqrt()\n",
    "\n",
    "def compute_lddt(ground_truth_atoms, predicted_atoms, cutoff=30.0, thresholds=[1.0, 2.0, 4.0, 8.0]):\n",
    "    \"\"\"\n",
    "    Computes the lDDT score between ground truth and predicted atoms.\n",
    "\n",
    "    Parameters:\n",
    "        ground_truth_atoms (np.array): Nx3 array of ground truth atom coordinates.\n",
    "        predicted_atoms (np.array): Nx3 array of predicted atom coordinates.\n",
    "        cutoff (float): Distance cutoff in Ångstroms to consider neighbors. Default is 30 Å.\n",
    "        thresholds (list): List of thresholds in Ångstroms for the lDDT computation. Default is [0.5, 1.0, 2.0, 4.0].\n",
    "\n",
    "    Returns:\n",
    "        float: The lDDT score.\n",
    "    \"\"\"\n",
    "    # Number of atoms\n",
    "    num_atoms = ground_truth_atoms.shape[0]\n",
    "\n",
    "    # Initialize array to store lDDT fractions for each threshold\n",
    "    fractions = np.zeros(len(thresholds))\n",
    "\n",
    "    for i in range(num_atoms):\n",
    "        # Get the distances from atom i to all other atoms for both ground truth and predicted atoms\n",
    "        gt_distances = np.linalg.norm(ground_truth_atoms[i] - ground_truth_atoms, axis=1)\n",
    "        pred_distances = np.linalg.norm(predicted_atoms[i] - predicted_atoms, axis=1)\n",
    "\n",
    "        # print(gt_distances)\n",
    "        # print(pred_distances)\n",
    "        # exit()\n",
    "        # Apply the cutoff to consider only distances within the cutoff range\n",
    "        mask = (gt_distances > 0) & (gt_distances < cutoff)\n",
    "\n",
    "        # Calculate the absolute difference between ground truth and predicted distances\n",
    "        distance_diff = np.abs(gt_distances[mask] - pred_distances[mask])\n",
    "\n",
    "        # Filter out any NaN values from the distance difference calculation\n",
    "        valid_mask = ~np.isnan(distance_diff)\n",
    "        distance_diff = distance_diff[valid_mask]\n",
    "\n",
    "        # Compute the fractions for each threshold\n",
    "        for j, threshold in enumerate(thresholds):\n",
    "            if len(distance_diff)>0:\n",
    "                fractions[j] += np.mean(distance_diff < threshold)\n",
    "    # print(fractions)\n",
    "    # print(num_atoms)\n",
    "\n",
    "    # Average the fractions over the number of atoms\n",
    "    fractions /= num_atoms\n",
    "\n",
    "    # The final lDDT score is the average of these fractions\n",
    "    lddt_score = np.mean(fractions)\n",
    "\n",
    "    return lddt_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs=config['epochs']\n",
    "# cos_epoch=config['cos_epoch']\n",
    "cos_epoch=5\n",
    "\n",
    "\n",
    "best_loss=np.inf\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=0.0, lr=0.0002) #no weight decay following AF\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "#for cycle in range(2):\n",
    "\n",
    "criterion=torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "#scaler = GradScaler()\n",
    "\n",
    "schedule=torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=(epochs-cos_epoch)*len(train_loader)//batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 6.340250492095947:   6%|▋         | 81/1288 [00:20<05:00,  4.02it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m gt_xyz[torch.isnan(gt_xyz)]=\u001b[32m0\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# print('start sequence',sequence.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m pred_xyz = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m     27\u001b[39m loss = dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loss!=loss:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\solba\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\solba\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 208\u001b[39m, in \u001b[36mWuSubSol.forward\u001b[39m\u001b[34m(self, src)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src):\n\u001b[32m    206\u001b[39m     pairwise_feature = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     src = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# L*d_model\u001b[39;00m\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# print('after embedding', src.shape)\u001b[39;00m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i,layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.encoder_layers):\n\u001b[32m    213\u001b[39m         \u001b[38;5;66;03m# print(\"before\",src.shape)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\solba\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\solba\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mEmbedSequence.forward\u001b[39m\u001b[34m(self, sequence)\u001b[39m\n\u001b[32m     63\u001b[39m seq_len = \u001b[38;5;28mlen\u001b[39m(sequence.squeeze())\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# print(seq_len)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m pos_encoding = \u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m sequence = sequence.long()\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.embedding(sequence) + pos_encoding\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mpos_encoder\u001b[39m\u001b[34m(seq_len, d_model)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_model):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         result[pos][i] = np.sin(pos / (\u001b[32m10000\u001b[39m ** (i / d_model)))\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     14\u001b[39m         result[pos][i] = np.cos(pos / (\u001b[32m10000\u001b[39m ** ((i - \u001b[32m1\u001b[39m) / d_model)))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "version_name = 'ribonanza2_5models'\n",
    "\n",
    "best_val_loss=99999999999\n",
    "loss_df = pd.DataFrame(columns=['epoch', 'train_loss', 'val_loss'])\n",
    "\n",
    "# print(type(train_loader))\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    tbar=tqdm(train_loader)\n",
    "    total_loss=0\n",
    "    train_loss=0\n",
    "\n",
    "    for idx, batch in enumerate(tbar):\n",
    "        #try:\n",
    "        sequence=batch['sequence']#.cuda()\n",
    "        gt_xyz=batch['xyz'].squeeze()#.cuda()\n",
    "\n",
    "        mask=~torch.isnan(gt_xyz)\n",
    "        gt_xyz[torch.isnan(gt_xyz)]=0\n",
    "        # print('start sequence',sequence.shape)\n",
    "\n",
    "        pred_xyz = model(sequence).squeeze()\n",
    "\n",
    "        loss = dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "\n",
    "        if loss!=loss:\n",
    "            stop\n",
    "\n",
    "        try:\n",
    "          (loss/batch_size).backward()\n",
    "        except:\n",
    "          print(gt_xyz.shape)\n",
    "\n",
    "        if (idx+1)%batch_size==0 or idx+1 == len(tbar):\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            # scaler.scale(loss/batch_size).backward()\n",
    "            # scaler.unscale_(optimizer)\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "\n",
    "            if (epoch+1)>cos_epoch:\n",
    "                schedule.step()\n",
    "        \n",
    "        total_loss += loss\n",
    "        train_loss = total_loss/(idx+1)\n",
    "\n",
    "        tbar.set_description(f\"Epoch {epoch + 1} Loss: {total_loss/(idx+1)}\")\n",
    "\n",
    "    ### Validation\n",
    "    tbar=tqdm(val_loader)\n",
    "      \n",
    "    model.eval()\n",
    "    val_preds=[]\n",
    "    val_loss=0\n",
    "\n",
    "    for idx, batch in enumerate(tbar):\n",
    "        sequence=batch['sequence']#.cuda()\n",
    "        gt_xyz=batch['xyz'].squeeze()#.cuda().squeeze()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_xyz=model(sequence).squeeze()\n",
    "            loss = dRMAE(pred_xyz,pred_xyz,gt_xyz,gt_xyz) + align_svd_mae(pred_xyz, gt_xyz)\n",
    "\n",
    "        val_loss+=loss\n",
    "        val_preds.append([gt_xyz.cpu().numpy(),pred_xyz.cpu().numpy()])\n",
    "\n",
    "    val_loss=val_loss/len(tbar)\n",
    "    print(f\"val loss: {val_loss}\")\n",
    "\n",
    "    save_df = pd.DataFrame({'epoch': [epoch], 'train_loss': [train_loss], 'val_loss': [val_loss]})\n",
    "    loss_df = pd.concat([loss_df, save_df], ignore_index=True)\n",
    "\n",
    "    ## Check Best Loss .pt and Save\n",
    "    if val_loss<best_val_loss:\n",
    "        best_val_loss=val_loss\n",
    "        best_preds=val_preds\n",
    "        torch.save(model.state_dict(),f'/Save_Data/{version_name}_{epochs}_best.pt')\n",
    "\n",
    "    # 1.053595052265986 train loss after epoch 0\n",
    "torch.save(model.state_dict(),f'/Save_Data/{version_name}_{epochs}_last.pt')\n",
    "\n",
    "# Save Loss,\n",
    "\n",
    "loss_df.to_csv(f'/Save_Data/{version_name}_{epochs}_loss.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
